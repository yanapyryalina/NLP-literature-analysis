{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Literature Analysis\n",
    "\n",
    "### Reading is great. And with so many amazing books out there also come great movies, reviews, and summaries. Reading those reviews and watching those films often only gives us a picture of what the book is actually like, though. With the power of data science and natural language processing, I am able to bring another dimension to how we understand literature.\n",
    "\n",
    "For this project, I am looking at the following eight writings:\n",
    "* **The Foundation by Isaac Asimov** - a book I am currently reading, by my favorite sci-fi writer \n",
    "* **A Clockwork Orange by Anthony Burgess** - the writing behind a famous extravagant horror movie by Stanley Kubrik, a book with a unique writing style and vocabulary\n",
    "* **Comments to the Society of the Spectacle by Guy Debord** - a continuation of a book I was taught in university about the influence of the capitalist media on the society\n",
    "* **A Brief History of Time by Stephen Hawking** - a book that excited millions about the workings of our universe\n",
    "* **For Whom the Bell Tolls by Ernest Hemingway** - a writing with a unique writing style and themes specific to American writers\n",
    "* **Carrie by Stephen King** - one of the most well-known horrors out there\n",
    "* **The Hobbit by J.R.R. Tolkien** - a very long journey by very short people, one that so many people and communities hold dear to their heart\n",
    "* **Slaughterhouse Five by Kurt Vonnegut** - a book highly recommended to me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our clean data, we will use it to do some exploratory data analysis.\n",
    "\n",
    "\n",
    "We are going to look at the following for each writer's:\n",
    "\n",
    "1. **Most common words** - find these and create word clouds\n",
    "2. **Size of vocabulary** - look number of unique words and compare authors' vocabulary and book lengths \n",
    "\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. Most common words - **Word Clouds**\n",
    "    - Find top 30 words said by each author\n",
    "    - Exclude words that appear in more than 50% of the books\n",
    "    - Update the document-term matrix - add these common words to stop words\n",
    "    - Create word cloud using WordCloud and matplotlib libraries\n",
    "    \n",
    "    \n",
    "2. **Vocabulary and Length - Unique and Total** words\n",
    "    - Find non-zero items in the document-term matrix and input the numbers into a new dataframe\n",
    "    - Find the total number of words that a writer uses \n",
    "    \n",
    "    \n",
    "3. **Bar-plot** and **Scatter-plot** findings\n",
    "    - Make a bar-plot of unique and total words of authoer using numpy and matplotlib\n",
    "    - Make a scatter-plot of Book-Length vs Vocabulary using matplotlib\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read in the document-term matrix\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_pickle('dtm.pkl')\n",
    "data = data.transpose() # transpose into a term-document matrix\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('dtm.pkl')\n",
    "data = data.transpose() # transpose into a term-document matrix\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top 30 words said by each writer\n",
    "top_dict = {} \n",
    "for c in data.columns: # for each writer (represented by a column)\n",
    "    top = data[c].sort_values(ascending=False).head(30) # sort the words (values of rows) in descending order and take first 30\n",
    "    top_dict[c]= list(zip(top.index, top.values)) # put the top 30 words into a discionary\n",
    "\n",
    "top_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the top 15 words said by each writer\n",
    "for writer, top_words in top_dict.items(): # for each writer and his top_words in items of dictionary\n",
    "    print(writer)\n",
    "    print(', '.join([word for word, count in top_words[0:14]])) # format and print top 15\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** At this point, we could go on and create word clouds. However, by looking at these top words, we can see that some of them have very little meaning and could be added to a stop words list, so let's do just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the most common top words --> add them to the stop word list\n",
    "from collections import Counter\n",
    "\n",
    "# Let's first pull out the top 30 words for each writer - basically reformat into a list\n",
    "words = [] # create a new blank list\n",
    "for writer in data.columns: \n",
    "    top = [word for (word, count) in top_dict[writer]] # take from our previously created top_dict\n",
    "    for t in top: # take the words from previously created word list called top\n",
    "        words.append(t) \n",
    "        \n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's aggregate this list and identify the most common words along with how many books they occur in\n",
    "Counter(words).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If more than half of the writers have it as a top word, exclude it from the list\n",
    "add_stop_words = [word for word, count in Counter(words).most_common() if count > 4]\n",
    "add_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's update our document-term matrix with the new list of stop words\n",
    "from sklearn.feature_extraction import text \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Read in cleaned data\n",
    "data_clean = pd.read_pickle('data_clean.pkl')\n",
    "\n",
    "# Add new stop words\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n",
    "\n",
    "# Recreate document-term matrix\n",
    "cv = CountVectorizer(stop_words=stop_words) # create a new instance of CountVectorizer object\n",
    "data_cv = cv.fit_transform(data_clean.writing) # fit and transform to learn the vocabulary and encode each document with a vector\n",
    "data_stop = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names()) # actually recreate the matrix\n",
    "data_stop.index = data_clean.index # initialize the index\n",
    "\n",
    "# Pickle it for later use\n",
    "import pickle\n",
    "pickle.dump(cv, open(\"cv_stop.pkl\", \"wb\"))\n",
    "data_stop.to_pickle(\"dtm_stop.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make some word clouds!\n",
    "# In order to run need - Terminal / Anaconda Prompt: conda install -c conda-forge wordcloud\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "wc = WordCloud(stopwords=stop_words, background_color=\"white\", colormap=\"Dark2\",\n",
    "               max_font_size=150, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the output dimensions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [16, 6]\n",
    "\n",
    "full_names = ['Isaac Asimov', 'Anthony Burgess', 'Guy Debord', 'Stephen Hawking', 'Ernest Hemingway', \n",
    "              'Stephen King', 'J.R.R. Tolkien', 'Kurt Vonnegut']\n",
    "\n",
    "\n",
    "# Create subplots for each writer\n",
    "for index, writer in enumerate(data.columns):\n",
    "    wc.generate(data_clean.writing[writer])\n",
    "    \n",
    "    plt.subplot(3, 4, index+1)\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(full_names[index])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findings\n",
    "\n",
    "### Isaac Asimov\n",
    "- **Hardin vs Mallow** - The story seems to be divided very evenly between Hardin and Mallow\n",
    "- **Anacreon vs Terminus** - Anacreon, a smaller but rapidly developing planet, seems to be much more of a concern or interest than Terminus - Anacreon's more developped and seemingly central to story neighbor\n",
    "\n",
    "### Anthony Burgess\n",
    "- **Root of confusion** - The word cloud is about as confusing as the actual book (no offense Anthony). One reason for such confusion could be because other than Brother, most used words are not English\n",
    "\n",
    "### Guy Debord\n",
    "- **Facts** - A word 'fact' appears a lot, while the critics find little to no facts in Debord's writings\n",
    "- **New vs History** - Debord seems to focus more on 'new' than 'history'\n",
    "\n",
    "### Stephen Hawking\n",
    "- **Citing himself?** - Stephen Hawking seems to mention himself often enough to appear in the word cloud! And he has a reason for that... After all, he was arguably the greatest astrophysicist in the world. So is he admitting that too?\n",
    "\n",
    "### Ernest Hemingway\n",
    "- **Balance** - Hemingway seems to have the most balance between most-often used words - each word and character are pretty competitive between each other. What does that say about his writing?\n",
    "\n",
    "### Stephen King\n",
    "- In contrast, Stephen King seems to be pretty straight-forward with his themes\n",
    "- Yet his writing is so great!\n",
    "\n",
    "### J.R.R. Tolkien\n",
    "- **Sorry Gendalf...** But the goblin seems to be more popular!\n",
    "- There seems to be **more dark than light**\n",
    "- And the way seems to be **long, great, and far**\n",
    "\n",
    "### Kurt Vonnegut\n",
    "- **Billy** seems to be the star of the story, along with **America** and **War**\n",
    "\n",
    "### Although it may feel like we know these popular authors from the book-based movies, summaries, and reports, a relatively simple data analysis can show that there is much more to these authors. \n",
    "### Evidently, even in fantasy, horror, and science fiction authors show their personalities and quirks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of words - Unique and Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose from the options of full_names below depending on what you find easier for understand the graphs' results\n",
    "# full_names = ['Asimov - The Foundation', 'Burgess - Clockwork Orange', 'Debord - Comments to the Society of the Spectacle', 'Hawking - A Brief History of Time', 'Hemingway - For Whom the Bell Tolls', 'King - Carrie', 'Tolkien - The Hobbit', 'Vonnegut - Slaughterhouse Five']\n",
    "full_names = ['Isaac Asimov', 'Anthony Burgess', 'Guy Debord', 'Stephen Hawking', 'Ernest Hemingway', 'Stephen King', 'J.R.R. Tolkien', 'Kurt Vonnegut']\n",
    "\n",
    "\n",
    "# Find the number of unique words that each writer uses\n",
    "\n",
    "# Identify the non-zero items in the document-term matrix, meaning that the word occurs at least once\n",
    "unique_list = []\n",
    "for writer in data.columns:\n",
    "    uniques = data[writer].nonzero()[0].size # number of unique words is the size of data[writer].nonzero()[0]\n",
    "    unique_list.append(uniques) # append unique_list by the integer number of unique words that writer has\n",
    "\n",
    "# Create a new dataframe that contains this unique word count and length of the writing\n",
    "data_words = pd.DataFrame(list(zip(full_names, unique_list)), columns=['writer', 'unique_words']) # create the data frame\n",
    "data_unique_sort = data_words.sort_values(by='unique_words') # sort by vocabulary size in ascending order\n",
    "data_unique_sort = data_unique_sort.set_index('writer') # make writer name the index instead of the writers' order number\n",
    "data_unique_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the total number of words that a writer uses\n",
    "total_list = []\n",
    "for writer in data.columns: # for each writer (represented by columns of data)\n",
    "    totals = sum(data[writer]) # sum up all the numbers of words (rows of data) per writer (columns of data)\n",
    "    total_list.append(totals) # add the sums of each writers' words to total_list\n",
    "\n",
    "data_words['total_words'] = total_list # add a new column\n",
    "\n",
    "# Create a new dataframe that contains this unique word count and length of the writing\n",
    "data_words = pd.DataFrame(list(zip(full_names, unique_list, total_list)), columns=['writer', 'unique_words', 'total_words'])\n",
    "data_total_sort = data_words.sort_values(by='total_words') # sort by length of the writing in ascending order\n",
    "data_total_sort = data_total_sort.set_index('writer') # set writer as the index of the dataframe to avoid confusion\n",
    "data_total_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot our findings\n",
    "import numpy as np\n",
    "\n",
    "y_pos = np.arange(len(data_words))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.barh(y_pos, data_unique_sort.unique_words, align='center')\n",
    "plt.yticks(y_pos, data_unique_sort.index)\n",
    "plt.title('Number of Unique Words', fontsize=20)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(y_pos, data_total_sort.total_words, align='center')\n",
    "plt.yticks(y_pos, data_total_sort.index)\n",
    "plt.title('Number of Total Words', fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a scatter plot of our findings\n",
    "plt.rcParams['figure.figsize'] = [10, 8]\n",
    "\n",
    "for i, writer in enumerate(data_total_sort.index):\n",
    "    x = data_total_sort.total_words.loc[writer] # total words found in data_total_sort table, total_words column\n",
    "    y = data_total_sort.unique_words.loc[writer] # unique words found in data_total_sort table, unique_words column\n",
    "    plt.scatter(x, y, color='blue')\n",
    "    plt.text(x+1.5, y+0.5, list(data_total_sort.index.values)[i], fontsize=10) # set the names near the dots in order shown in data_total\n",
    "    plt.xlim(0, 40000) \n",
    "    \n",
    "plt.title('Vocabulary to Book Length Ratios', fontsize=20) # name the graph\n",
    "plt.xlabel('Book Length', fontsize=15) # set name for x axis\n",
    "plt.ylabel('Vocabulary', fontsize=15) # set name for y axis\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Big universe and small vocabulary** - Surprisingly, Stephen Hawking is on the low end of vocabulary sizes. I expected his book 'A Brief History of Time' to have many technical terms, but it ended up having a low number of unique words. However, it does make sense! The purpose of this book was to explain complex astrophysics concepts in simple and understandable language, which Stephen Hawking indeed did a good job of!\n",
    "\n",
    "\n",
    "- **Not enough Russian words** - It was also surprising to me to see Anthony Burgess' A Clockwork Orange on the slightly lower end of vocabulary size compared to others. With how many extravagant Russian-originated slang words there are in the book, their number still could not top Hemingway's vocabulary.\n",
    "\n",
    "\n",
    "- **Horror & Sci-fi Campions** - Again surprisingly, Carrie (by Stephen King) and Foundation (by Isaac Asimov) had similarly wide vocabularies and lengths despite such different genres. Also, such a high-vocab statistic for King was a contrast to his word cloud. Looking at the word cloud (with leading words Carrie, momma, eye, hand), I thought his vocabulary would be pretty narrow, but, in reality, Stephen King got to the very top, almost beating Asimov's space-travel vocabulary.\n",
    "\n",
    "\n",
    "- **Long journey, medium vocab** - Despite having the longest journey, The Hobbit had a relatively medium-sized vocabulary. Just like in A Clockwork Orange, I imagined that The Hobbit's lexicon would be full of world-specific words, but it ended up being just a tiny bit above the average, ranking almost equal to Kurt Vonnegut's vocabulary size.\n",
    "\n",
    "\n",
    "### As we can see, more data analysis can not only bring new insights but also alter the previous judgements. \n",
    "### To me, this was a good reminder to not judge a book by its... wordcloud. \n",
    "### To keep learning and to never stop questioning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next up - Sentiment Analysis!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
