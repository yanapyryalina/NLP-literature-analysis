{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Literature Analysis\n",
    "\n",
    "### Reading is great. And with so many amazing books out there also come great movies, reviews, and summaries. Reading those reviews and watching those films often only gives us a picture of what the book is actually like, though. With the power of data science and natural language processing, I am able to bring another dimension to how we understand literature.\n",
    "\n",
    "For this project, I am looking at the following eight writings:\n",
    "* **The Foundation by Isaac Asimov** - a book I am currently reading, by my favorite sci-fi writer \n",
    "* **A Clockwork Orange by Anthony Burgess** - the writing behind a famous extravagant horror movie by Stanley Kubrik, a book with a unique writing style and vocabulary\n",
    "* **Comments to the Society of the Spectacle by Guy Debord** - a continuation of a book I was taught in university about the influence of the capitalist media on the society\n",
    "* **A Brief History of Time by Stephen Hawking** - a book that excited millions about the workings of our universe\n",
    "* **For Whom the Bell Tolls by Ernest Hemingway** - a writing with a unique writing style and themes specific to American writers\n",
    "* **Carrie by Stephen King** - one of the most well-known horrors out there\n",
    "* **The Hobbit by J.R.R. Tolkien** - a very long journey by very short people, one that so many people and communities hold dear to their heart\n",
    "* **Slaughterhouse Five by Kurt Vonnegut** - a book highly recommended to me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will use Markov chains for very basic text generation. \n",
    "\n",
    "We will make the basic assumption of Markov chains - that the next word is only dependent on the previous word.\n",
    "\n",
    "*For this task with Markov Chains, I chose to use the defaultdict library because it allows to efficiently create a dictionary chain of words from our corpus on the go (in a loop), avoiding KeyErrors*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Select text to imitate\n",
    "\n",
    "\n",
    "2. **Create a Markov Chain function** and apply it to the author of your choice\n",
    "    - Import defaultdict library from collections\n",
    "    - Input a string of text\n",
    "    - Tokenize the text by word, but include punctuation\n",
    "    - Initialize a default dictionary to hold all of the words and their connections\n",
    "    - Create a zipped list of all of the word pairs and put them in a dictionary format (word : list of connecting words)\n",
    "    - Convert the default dictionary back into a regular dictionary and return it\n",
    "\n",
    "    \n",
    "    \n",
    "3. Create a **Sentence Generator function**\n",
    "    - Input the chosen author's Markov Chain and desired length of sentence\n",
    "    - Capitalize the first word to create a more sentence-like formatting\n",
    "    - Follow the Markov Chain text generation method by generating the second word from the value list, then third, and repeating until the end of sentence \n",
    "    - End with a period to complete the sentence formatting\n",
    "\n",
    "\n",
    "4. **Generate sentences** based on the writer of your choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select text to imitate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the corpus, including punctuation!\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_pickle('corpus.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will choose the writer to imitate by copying in data.writing.loc['name_of_author'] and later pasting it into Step 1 shown below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Markov Chain Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to build a simple Markov chain function that creates a dictionary:\n",
    "* The keys should be all of the words in the corpus\n",
    "* The values should be a list of the words that follow the keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def markov_chain(text):\n",
    "    '''The input is a string of text and the output will be a dictionary with each word as\n",
    "       a key and each value as the list of words that come after the key in the text.'''\n",
    "    \n",
    "    # Tokenize the text by word, though including punctuation\n",
    "    words = text.split(' ')\n",
    "    \n",
    "    # Initialize a default dictionary to hold all of the words and next words\n",
    "    m_dict = defaultdict(list)\n",
    "    \n",
    "    # Create a zipped list of all of the word pairs and put them in word: list of next words format\n",
    "    for current_word, next_word in zip(words[0:-1], words[1:]):\n",
    "        m_dict[current_word].append(next_word)\n",
    "\n",
    "    # Convert the default dict back into a dictionary\n",
    "    m_dict = dict(m_dict)\n",
    "    return m_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Text Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to create a function that generates sentences. It will take two things as inputs:\n",
    "* The dictionary we just created\n",
    "* The number of words we want generated\n",
    "\n",
    "Here are some of my favorite examples of generated sentences:\n",
    "\n",
    "> Stephen King: 'Comment. Nobody was overcast and sanitary napkins, chanting, laughing, shrieking of course, forbade her heart..'\n",
    "\n",
    "> Guy Debord: 'Erasure of the century language of goods is insignificant or in this mystery is genuine.'\n",
    "\n",
    "> Stephen Hawking: 'Suggests, cosmic censorship hypothesis tells us the inner edge of one ignored the very close.'\n",
    "\n",
    "> J.R.R. Tolkien: 'Loosened his door, and giving his ring of the balance as if he had baked.'\n",
    "\n",
    "> J.R.R. Tolkien: 'Grandmother, teaching his legs with them hoping against the chill flame, beating wigs bear to.'\n",
    "    \n",
    "> J.R.R. Tolkien: 'Saucer, and Bilbo had lost the foot of the foot right away.'\n",
    "    \n",
    "> J.R.R. Tolkien: '\"Try,\" said a gathering together! There was not forbear to sniff.'\n",
    "    \n",
    "> J.R.R. Tolkien: 'What about the hobbit? He slashed the current market value'\n",
    "\n",
    "> Isaac Asimov: 'Sake, as to admit you speak, Hardin. And two; after Emperor would one of Imperial.'\n",
    "\n",
    "> Ernest Hemingway: 'Material and headed toward Segovia at the cup out and the gipsyâ€™s voice thickening.'\n",
    "\n",
    "> Kurt Vonnegut: 'Architect. The atmosphere now, big kiss. She had been stolen from the opinion of his.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_sentence(chain, count=15):\n",
    "    '''Input a dictionary in the format of key = current word, value = list of next words\n",
    "       along with the number of words you would like to see in your generated sentence.'''\n",
    "\n",
    "    # Capitalize the first word\n",
    "    word1 = random.choice(list(chain.keys())) # pick the first word from a list of words in our dictionary\n",
    "    sentence = word1.capitalize() # capitalize\n",
    "\n",
    "    # Generate the second word from the value list. Set the new word as the first word. Repeat.\n",
    "    for i in range(count-1): \n",
    "        word2 = random.choice(chain[word1]) # for word2, choose a random word from the list of next words from word1\n",
    "        word1 = word2 # update the word1 to continue the loop\n",
    "        sentence += ' ' + word2 # add a space between the words\n",
    "\n",
    "    # End it with a period\n",
    "    sentence += '.'\n",
    "    return(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps for generating sentences from an author\n",
    "\n",
    "**Step 1** - Select the text to imitate (data.writing.loc['name_of_author'])\n",
    "\n",
    "\n",
    "**Step 2** - Create the markov chain dictionary from selected text markov_chain(data.writing.loc['name_of_author'])\n",
    "\n",
    "\n",
    "**Step 3** - Generate a sentence using the markov chain dictionary you created generate_sentence(markov_chain(data.writing.loc['name_of_author']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isaac Asimov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - most inside - Select the text to imitate\n",
    "# Step 2 - Create the markov chain dictionary from the selected text\n",
    "# step 3 - most outside - Generate a sentence  \n",
    "\n",
    "generate_sentence(markov_chain(data.writing.loc['asimov']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# J.R.R. Tolkien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_sentence(markov_chain(data.writing.loc['tolkien']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guy Debord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_sentence(markov_chain(data.writing.loc['debord']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anthony Burgess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_sentence(markov_chain(data.writing.loc['burgess']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stephen Hawking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_sentence(markov_chain(data.writing.loc['hawking']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ernest Hemingway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_sentence(markov_chain(data.writing.loc['hemingway']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stephen King"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_sentence(markov_chain(data.writing.loc['king']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kurt Vonnegut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_sentence(markov_chain(data.writing.loc['vonnegut']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
